{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/step-cheng/mnist_from_scratch/blob/main/mnist_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gX_jL5YjUe4A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from os.path import join\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle(x,y):\n",
        "  pattern = np.random.permutation(y.size)\n",
        "  x, y = x[pattern,:,:], y[pattern]\n",
        "  return x, y\n",
        "\n",
        "def one_hot_encode(labels):\n",
        "  one_hot = np.zeros((10,labels.size))\n",
        "  one_hot[labels, range(labels.size)] = 1\n",
        "  return one_hot\n",
        "\n",
        "def normalize(data):\n",
        "  data = data * (1 / 255)\n",
        "  return data"
      ],
      "metadata": {
        "id": "yTcShflRazPi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train, y_train = shuffle(x_train, y_train)\n",
        "one_hot_Y = one_hot_encode(y_train)\n",
        "\n",
        "img_data = np.reshape(x_train,(x_train.shape[0],784)).T\n",
        "assert img_data.shape == (784,60000)\n",
        "assert one_hot_Y.shape == (10,60000)\n",
        "\n",
        "img_data = normalize(img_data)\n"
      ],
      "metadata": {
        "id": "lnz-WvkTgmtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90dd5e49-5678-41f3-abc2-95d10daaadb6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_image(img, label):\n",
        "    img = np.reshape(img.T, (28,28))\n",
        "    num = np.where(label == 1)\n",
        "    plt.figure()\n",
        "    plt.title(f'Image number: {num[0]}')\n",
        "    plt.imshow(img, cmap=plt.cm.gray)\n"
      ],
      "metadata": {
        "id": "042XYqbCg0aJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize(dims):\n",
        "  params = {}\n",
        "  for i in range(1, len(dims)):\n",
        "      params['W' + str(i)] = np.random.randn(dims[i], dims[i-1]) * np.sqrt(1/(dims[i]))\n",
        "      params['b' + str(i)] = np.random.randn(dims[i], 1) * np.sqrt(1/dims[i])\n",
        "  return params\n"
      ],
      "metadata": {
        "id": "e4DOVKcDmazd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(Z):\n",
        "  return np.maximum(Z,0)\n",
        "\n",
        "def softmax(Z):\n",
        "  Z_ = Z - np.max(Z, axis = 0, keepdims = True)\n",
        "  A = np.exp(Z_) / np.sum(np.exp(Z_), axis = 0, keepdims = True)\n",
        "  return A\n",
        "\n",
        "def forward_pass(X, params):\n",
        "  L = len(params)//2\n",
        "\n",
        "  forward = {}\n",
        "  forward['A0'] = X\n",
        "\n",
        "  for i in range(1,L):\n",
        "    forward['Z'+str(i)] = np.dot(params['W'+str(i)], forward['A'+str(i-1)]) + params['b'+str(i)]\n",
        "    forward['A'+str(i)] = relu(forward['Z'+str(i)])\n",
        "\n",
        "  forward['Z'+str(L)] = np.dot(params['W'+str(L)], forward['A'+str(L-1)]) + params['b'+str(L)]\n",
        "  forward['A'+str(L)] = softmax(forward['Z'+str(L)])\n",
        "\n",
        "  return forward\n"
      ],
      "metadata": {
        "id": "NEPJRxcEoaVw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(A, Y):\n",
        "  assert A.shape == Y.shape\n",
        "  pred = np.zeros_like(A)\n",
        "  pred[np.argmax(A, axis = 0), range(A.shape[1])] = 1\n",
        "  acc = np.count_nonzero(pred + Y == 2) / Y.shape[1]\n",
        "  return acc"
      ],
      "metadata": {
        "id": "ixW602CBtdD1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu_deriv(A):\n",
        "  return A > 0\n",
        "\n",
        "def softmax_crossentropy_deriv(A, Y):\n",
        "  return A - Y\n",
        "\n",
        "def back_pass(forward, params, Y):\n",
        "  L = len(params) //2\n",
        "\n",
        "  grads = {}\n",
        "\n",
        "  # cross-entropy loss is calculated by averaging the loss over the sample size, thus the upstream gradient is 1/sample size\n",
        "  N = Y.shape[1]\n",
        "\n",
        "  # grads['dZ'+str(L)] = 1 * softmax_crossentropy_deriv(forward['A'+str(L)], Y)\n",
        "  # # grads['dW'+str(L)] = np.dot(dZ, forward['A'+str(L-1)].T)\n",
        "  # grads['dW'+str(L)] = 1/N * np.dot(grads['dZ'+str(L)], forward['A'+str(L-1)].T)\n",
        "  # grads['db'+str(L)] = 1/N * np.sum(grads['dZ'+str(L)], axis = 1, keepdims=True)\n",
        "  # assert grads['db'+str(L)].shape == params['b'+str(L)].shape\n",
        "\n",
        "  # for i in range(L-1,0,-1):\n",
        "  #   # grads['dZ'+str(i)] = np.multiply(np.dot(params['W'+str(i+1)].T, grads['dZ'+str(i+1)]), relu_deriv(forward['Z'+str(i)]))\n",
        "  #   grads['dZ'+str(i)] = np.dot(params['W'+str(i+1)].T, grads['dZ'+str(i+1)]) * relu_deriv(forward['Z'+str(i)])\n",
        "  #   # grads['dW'+str(i)] = np.dot(dZ, forward['A'+str(i-1)].T)\n",
        "  #   grads['dW'+str(i)] = 1/N * np.dot(grads['dZ'+str(i)], forward['A'+str(i-1)].T)\n",
        "  #   grads['db'+str(i)] = 1/N * np.sum(grads['dZ'+str(i)], axis = 1, keepdims=True)\n",
        "  #   assert grads['db'+str(i)].shape == params['b'+str(i)].shape\n",
        "\n",
        "  # don't need to store dZ since it is not used for learning\n",
        "  dZ = 1 * softmax_crossentropy_deriv(forward['A'+str(L)], Y)\n",
        "  # grads['dW'+str(L)] = np.dot(dZ, forward['A'+str(L-1)].T)\n",
        "  # 1/N to normalize gradient? Seems to work better this way\n",
        "  grads['dW'+str(L)] = 1/N * np.dot(dZ, forward['A'+str(L-1)].T)\n",
        "  grads['db'+str(L)] = 1/N * np.sum(dZ, axis = 1, keepdims=True)\n",
        "  assert grads['db'+str(L)].shape == params['b'+str(L)].shape\n",
        "\n",
        "  for i in range(L-1,0,-1):\n",
        "    # grads['dZ'+str(i)] = np.multiply(np.dot(params['W'+str(i+1)].T, grads['dZ'+str(i+1)]), relu_deriv(forward['Z'+str(i)]))\n",
        "    dZ = np.dot(params['W'+str(i+1)].T, dZ) * relu_deriv(forward['Z'+str(i)])\n",
        "    # grads['dW'+str(i)] = np.dot(dZ, forward['A'+str(i-1)].T)\n",
        "    grads['dW'+str(i)] = 1/N * np.dot(dZ, forward['A'+str(i-1)].T)\n",
        "    grads['db'+str(i)] = 1/N * np.sum(dZ, axis = 1, keepdims=True)\n",
        "    assert grads['db'+str(i)].shape == params['b'+str(i)].shape\n",
        "\n",
        "  return grads\n"
      ],
      "metadata": {
        "id": "JflpQ1AsrhDn"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def learn(grads, params, rate):\n",
        "  L= len(params)//2\n",
        "\n",
        "  new_params = {}\n",
        "  for i in range(1, L + 1):\n",
        "    new_params['b'+str(i)] = params['b'+str(i)] - rate*grads['db'+str(i)]\n",
        "    new_params['W'+str(i)] = params['W'+str(i)] - rate*grads['dW'+str(i)]\n",
        "\n",
        "  return new_params"
      ],
      "metadata": {
        "id": "MVom3kLOyv2a"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(img_data, label_data, dims, iterations, rate):\n",
        "  params = initialize(dims)\n",
        "  L = len(params)//2\n",
        "  accuracies = []\n",
        "  for i in range(1, iterations+1):\n",
        "    forward = forward_pass(img_data, params)\n",
        "\n",
        "    acc = accuracy(forward['A'+str(L)], label_data)\n",
        "    accuracies.append(acc)\n",
        "\n",
        "    grads = back_pass(forward, params, label_data)\n",
        "    params = learn(grads, params, rate)\n",
        "\n",
        "    if i % 10 == 0: print(f'Accuracy at iteration {i}: {accuracies[i-1]}')\n",
        "  plt.figure()\n",
        "  plt.xlabel('training cycles')\n",
        "  plt.ylabel('accuracy (%)')\n",
        "  plt.plot(range(1,len(accuracies)+1), [100*a for a in accuracies])\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "LRPN1iHVxdaK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dimensions = [784, 128, 64, 10]\n",
        "\n",
        "iterations = 500\n",
        "rate = 0.05\n",
        "model(img_data, one_hot_Y, dimensions, iterations, rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "9lL5LWgY0UyC",
        "outputId": "220ab020-38d7-4a33-b7e2-b037204752af"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy at iteration 10: 0.4495\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-9e865e67f5d0>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-848f6ce84026>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(img_data, label_data, dims, iterations, rate)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mforward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-cba28daf0232>\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(X, params)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mforward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Z'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'W'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mforward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Z'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}